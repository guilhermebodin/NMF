{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando base e retirando colunas desnecessárias \n",
    "business_json_path = 'data-yelp/yelp_academic_dataset_business.json'\n",
    "data_business = pd.read_json(business_json_path, lines=True)\n",
    "drop_columns = ['name', 'address', 'postal_code', 'latitude', 'longitude', 'review_count', 'attributes', 'hours']\n",
    "data_business = data_business.drop(drop_columns, axis=1)\n",
    "\n",
    "# Filtrando apenas business da Pensilvânia (PA)\n",
    "final_business = data_business[data_business['state'] == 'PA']\n",
    "final_business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = 1000000\n",
    "# review_json_path = 'data/yelp_academic_dataset_review.json'\n",
    "# review = pd.read_json(review_json_path, lines=True, chunksize=size)\n",
    "\n",
    "# # Merge da base de dados de review com a base de dados de business já filtrada\n",
    "# chunk_list = []\n",
    "# for chunk_review in review:\n",
    "#     chunk_review = chunk_review.drop(['review_id', 'user_id','useful','funny','cool'], axis=1).rename(columns={'stars': 'review_stars'})\n",
    "#     chunk_merged = pd.merge(final_business, chunk_review, on='business_id', how='inner')\n",
    "#     print(f\"{chunk_merged.shape[0]} out of {size:,} related reviews\")\n",
    "#     chunk_list.append(chunk_merged)\n",
    "    \n",
    "# final_df = pd.concat(chunk_list, ignore_index=True, join='outer', axis=0)\n",
    "\n",
    "# # Gerando CSV de novo dataset\n",
    "# final_csv_name = \"yelp_reviews_PA.csv\"\n",
    "# final_df.to_csv(final_csv_name, index=False)\n",
    "\n",
    "final_df = pd.read_csv('data-yelp/yelp_reviews_PA.csv')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_reviews = 1500\n",
    "df_count = final_df.groupby(['business_id']).count()\n",
    "df_count = df_count[df_count['text']>=number_of_reviews].sort_values(by=['text'], ascending=False)\n",
    "print(df_count)\n",
    "top_reviews = df_count.index.values\n",
    "final_df = final_df[final_df['business_id'].isin(top_reviews)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análise da base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def word_count(x):\n",
    "    return len(x.split())\n",
    "\n",
    "final_df['words_count'] = final_df['text'].apply(word_count)\n",
    "print(final_df)\n",
    "print('Descrição estatística da quantidade de palavras dos reviews:\\n\\n', final_df['words_count'].describe())\n",
    "\n",
    "plt.hist(final_df['words_count'], bins=100, label='Quantidade de palavras')\n",
    "\n",
    "    \n",
    "reviews_1 = final_df[final_df['review_stars'] <= 1]\n",
    "reviews_2 = final_df[(final_df['review_stars'] <= 2) & (final_df['review_stars'] > 1)]\n",
    "reviews_3 = final_df[(final_df['review_stars'] <= 3) & (final_df['review_stars'] > 2)]\n",
    "reviews_4 = final_df[(final_df['review_stars'] <= 4) & (final_df['review_stars'] > 3)]\n",
    "reviews_5 = final_df[(final_df['review_stars'] <= 5) & (final_df['review_stars'] > 4)]\n",
    "\n",
    "labels = '1 star', '2 stars', '3 stars', '4 stars', '5 stars'\n",
    "sizes = [len(reviews_1), len(reviews_2), len(reviews_3), len(reviews_4), len(reviews_5)]\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "ax1.axis('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pré-processamento dos textos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "# lowercase\n",
    "texts = [text.lower() for text in final_df['text']]\n",
    "\n",
    "# remoção de números\n",
    "texts = [re.sub(r'\\d+', '', text) for text in texts]\n",
    "\n",
    "# remoção de pontuação\n",
    "translator = str.maketrans('', '', string.punctuation) \n",
    "texts = [text.translate(translator) for text in texts]\n",
    "\n",
    "# remoção de espaços em branco\n",
    "texts = [\" \".join(text.split()) for text in texts]\n",
    "\n",
    "\n",
    "final_df['text'] = texts\n",
    "# print(final_df[:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviews Negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 7\n",
    "max_df = 0.85\n",
    "min_df=3\n",
    "\n",
    "for business in top_reviews:\n",
    "    business_reviews = final_df[(final_df['business_id'] == business) & (final_df['review_stars'] <= 2)]['text']\n",
    "    print('\\n*****', business, '*****\\n')\n",
    "    print(data_business[data_business['business_id'] == business], ' \\n')\n",
    "    print('Dataset size:', len(business_reviews))\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_df=0.85, min_df=3, stop_words='english')\n",
    "    \n",
    "    vectors = vectorizer.fit_transform(business_reviews) \n",
    "    words = np.array(vectorizer.get_feature_names())\n",
    "    print('words', len(words), vectors.shape, '\\n')\n",
    "\n",
    "    nmf = NMF(n_components=n_components, solver=\"mu\")\n",
    "    W = nmf.fit_transform(vectors)\n",
    "    H = nmf.components_\n",
    "    \n",
    "    for i, topic in enumerate(H):\n",
    "         print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in words[topic.argsort()[-5:]]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reviews Positivos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 7\n",
    "max_df = 0.85\n",
    "min_df=5\n",
    "\n",
    "for business in top_reviews:\n",
    "    business_reviews = final_df[(final_df['business_id'] == business) & (final_df['review_stars'] > 4)]['text']\n",
    "    print('\\n*****', business, '*****\\n')\n",
    "    print(data_business[data_business['business_id'] == business], ' \\n')\n",
    "    print('Dataset size:', len(business_reviews))\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df, stop_words='english')\n",
    "    \n",
    "    vectors = vectorizer.fit_transform(business_reviews) \n",
    "    words = np.array(vectorizer.get_feature_names())\n",
    "    print('words', len(words), vectors.shape, '\\n')\n",
    "\n",
    "    nmf = NMF(n_components=n_components, solver=\"mu\")\n",
    "    \n",
    "    W = nmf.fit_transform(vectors)\n",
    "    H = nmf.components_\n",
    "\n",
    "    for i, topic in enumerate(H):\n",
    "         print(\"Topic {}: {}\".format(i + 1, \",\".join([str(x) for x in words[topic.argsort()[-5:]]])))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
